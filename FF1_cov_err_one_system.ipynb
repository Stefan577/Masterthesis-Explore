{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METHODS = [\n",
    "    #['cv_plus', 'lin', None],\n",
    "    #['jackknife_plus', 'lin', None],\n",
    "\n",
    "    ['cv_plus', 'lin_lasso', None],\n",
    "    ['jackknife_plus', 'lin_lasso', None],\n",
    "\n",
    "    ['cv_plus', 'cart', None],\n",
    "    ['jackknife_plus', 'cart', None],\n",
    "\n",
    "    ['cv_plus', 'rf', None],\n",
    "    ['jackknife_plus', 'rf', None],\n",
    "\n",
    "    ['cv_plus', 'kr', None],\n",
    "    ['jackknife_plus', 'kr', None],\n",
    "\n",
    "    # ['cv_plus', 'svr', None],\n",
    "    # ['jackknife_plus', 'svr', None],\n",
    "\n",
    "    #['cqr', 'lin_quant', None],\n",
    "    #['cqr', 'lgbm_quant', None],\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_folder_names(path):\n",
    "    folder_names = []\n",
    "    for item in os.listdir(path):\n",
    "        item_path = os.path.join(path, item)\n",
    "        if os.path.isdir(item_path) and item not in ['$RECYCLE.BIN', 'System Volume Information']:\n",
    "            folder_names.append(item)\n",
    "\n",
    "    return folder_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_column_values_above_alpha_to_alpha(df_func, column_name, alpha_func):\n",
    "    \"\"\"\n",
    "    Set values in a specific column of the DataFrame higher than alpha to alpha.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to process.\n",
    "    column_name (str): The name of the column to process.\n",
    "    alpha (int or float): The threshold value.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with values higher than alpha in the specified column set to alpha.\n",
    "    \"\"\"\n",
    "    df_func[column_name] = df_func[column_name].apply(lambda x: alpha_func if x and x > alpha_func else x)\n",
    "    return df_func"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_path = \"/mnt/e/Experiment_x264_energy\"\n",
    "sampling_strategies = get_folder_names(exp_path)\n",
    "sampling_strategies.remove(\"old\")\n",
    "print(sampling_strategies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#auswahl_test_strategien = [\"OW\", \"T-wise_2\", \"T-wise_3\"]\n",
    "auswahl_test_strategien = [\"Distance_1\", \"Distance_2\", \"Distance_3\"]\n",
    "# auswahl_test_strategien = [\"Distance_1\", \"Distance_2\", \"Distance_3\", \"Random_1\", \"Random_2\", \"Random_3\"]\n",
    "# auswahl_test_strategien = [\"Random_1\", \"Random_2\", \"Random_3\"]\n",
    "\n",
    "runs = np.empty(len(sampling_strategies), dtype=object)\n",
    "for i in range(len(sampling_strategies)):\n",
    "    runs[i] = get_folder_names(os.path.join(exp_path, sampling_strategies[i]))\n",
    "    print(runs[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_dfs = {}\n",
    "alpha = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for m in range(len(METHODS)):\n",
    "    ml_models = METHODS[m]\n",
    "    df = pd.DataFrame()\n",
    "    for s in range(len(auswahl_test_strategien)):\n",
    "        cov_dif = []\n",
    "        for r in runs[s]:\n",
    "            json_name = f\"{ml_models[0]}_{ml_models[1]}_{ml_models[2]}_result.txt\"\n",
    "            json_path = os.path.join(exp_path, auswahl_test_strategien[s], r, json_name)\n",
    "            try:\n",
    "                with open(json_path) as json_file:\n",
    "                    data = json.load(json_file)\n",
    "                    data[\"Cov_dif\"] = abs(data['coverage'] - (1 - alpha))\n",
    "                    cov_dif.append(data['Cov_dif'])\n",
    "            except FileNotFoundError:\n",
    "                print(f\"{auswahl_test_strategien[s]}: {r} has no Data for this ML-Model({ml_models})\")\n",
    "                cov_dif.append(None)\n",
    "        df[auswahl_test_strategien[s]] = cov_dif\n",
    "    result_dfs[m] = df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for m in range(len(METHODS)):\n",
    "    data_dict[f\"{METHODS[m]}\"] = result_dfs[m]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Liste für die kombinierten DataFrames\n",
    "combined_dfs = []\n",
    "\n",
    "# Durch alle DataFrames und Methoden iterieren\n",
    "for df, method in zip(result_dfs, METHODS):\n",
    "    method_str = \"\"\n",
    "    model_str = \"\"\n",
    "    if method[0] == \"cv_plus\":\n",
    "        method_str = \"CrossValidation+\"\n",
    "    if method[0] == \"jackknife_plus\":\n",
    "        method_str = \"Jackknife+\"\n",
    "\n",
    "    if method[1] == \"rf\":\n",
    "        model_str = \"RandomForest\"\n",
    "    if method[1] == \"kr\":\n",
    "        model_str = \"KernelRidge\"\n",
    "    if method[1] == \"cart\":\n",
    "        model_str = \"DecisionTree\"\n",
    "    if method[1] == \"lin_lasso\":\n",
    "        model_str = \"LinearLasso\"\n",
    "\n",
    "    result_dfs[df]['Method'] = method_str\n",
    "    result_dfs[df]['Model'] = model_str\n",
    "    combined_dfs.append(result_dfs[df])  # DataFrame zur Liste hinzufügen\n",
    "\n",
    "# Alle DataFrames zu einem einzelnen DataFrame kombinieren\n",
    "final_df = pd.concat(combined_dfs, ignore_index=True)\n",
    "final_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.8)\n",
    "\n",
    "# Liste der Spalten, die geplottet werden sollen\n",
    "#columns_to_plot = ['Random_1', 'Random_2', 'Random_3']\n",
    "columns_to_plot = auswahl_test_strategien\n",
    "\n",
    "# DataFrame in ein long format umwandeln, um seaborn FacetGrid zu verwenden\n",
    "df_long = final_df.melt(id_vars=['Method', 'Model'], value_vars=columns_to_plot, var_name='Random', value_name='Coverage Fehler')\n",
    "\n",
    "# Sortiere nach Method und Model für die richtige Anordnung\n",
    "df_long = df_long.sort_values(by=['Method', 'Model'])\n",
    "\n",
    "# FacetGrid erstellen\n",
    "g = sns.FacetGrid(df_long, row='Method', col='Model', hue='Random', sharex=True, sharey=True, height=3,  aspect=1.5)\n",
    "\n",
    "# KDE-Plots zu FacetGrid hinzufügen\n",
    "g.map(sns.kdeplot, 'Coverage Fehler', fill=True, cut=2)\n",
    "\n",
    "g.set(xlim=(0, 0.4), ylim=(0, 30))\n",
    "\n",
    "# Legende und Titel hinzufügen\n",
    "#g.add_legend()\n",
    "\n",
    "# Anpassung der Achsenbeschriftungen\n",
    "for ax, title in zip(g.axes.flat, df_long['Model'].unique()):\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Linke Beschriftungen anpassen\n",
    "for ax, row_val in zip(g.axes[:, 0], df_long['Method'].unique()):\n",
    "    ax.set_ylabel(f\"{row_val}\\n\\n Dichte\")\n",
    "\n",
    "# Remove titles for all but the first row\n",
    "for ax in g.axes[1:, :].flatten():\n",
    "    ax.set_title('')\n",
    "\n",
    "for ax in g.axes[0, 1:]:\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "for ax in g.axes[1, 1:]:\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "#g.fig.suptitle('KDE Plots for Different Methods and Models')\n",
    "\n",
    "# tight_layout anwenden\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "plt.legend(title='Sampling', bbox_to_anchor=(0.43, 2.34), loc='upper left', borderaxespad=0., frameon=True, fontsize=15)\n",
    "\n",
    "# Plot speichern, ohne dass die Beschriftungen abgeschnitten werden\n",
    "g.savefig(os.path.join(exp_path, \"distance-com-grid\"), bbox_inches='tight')\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Statistische Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "grouped = final_df.groupby(['Method', 'Model'])\n",
    "\n",
    "# Initialisierung eines Zählers für normalverteilte Kombinationen\n",
    "normal_count = 0\n",
    "\n",
    "# Anzahl der durchgeführten Tests (3 Tests pro Kombination)\n",
    "num_tests = 24\n",
    "\n",
    "# Signifikanzniveau\n",
    "alpha = 0.05\n",
    "\n",
    "# Anpassung des p-Werts durch Bonferroni-Korrektur\n",
    "adjusted_alpha = alpha / num_tests\n",
    "\n",
    "# Überprüfen der Normalverteilung für jede Gruppe\n",
    "for name, group in grouped:\n",
    "    # Shapiro-Wilk-Test für jede der Random-Spalten\n",
    "    shapiro_results = [stats.shapiro(group[col])[1] for col in ['Random_1', 'Random_2', 'Random_3']]\n",
    "    print(shapiro_results)\n",
    "    # Überprüfen, ob alle p-Werte größer sind als der angepasste Alpha-Wert\n",
    "    for p in shapiro_results:\n",
    "        if p > adjusted_alpha:\n",
    "            normal_count += 1\n",
    "    #if all(p > adjusted_alpha for p in shapiro_results):\n",
    "    #    normal_count += 1\n",
    "\n",
    "# Ausgabe der Anzahl normalverteilten Kombinationen\n",
    "normal_count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "results = []\n",
    "\n",
    "grouped = final_df.groupby(['Method', 'Model'])\n",
    "\n",
    "# Iteriere über jede Gruppe\n",
    "for (method, model), group in grouped:\n",
    "    # Kruskal-Wallis Test für Random_1 vs Distance_1\n",
    "    stat_1, p_1 = kruskal(group['Random_1'], group['Distance_1'])\n",
    "    # Kruskal-Wallis Test für Random_2 vs Distance_2\n",
    "    stat_2, p_2 = kruskal(group['Random_2'], group['Distance_2'])\n",
    "    # Kruskal-Wallis Test für Random_3 vs Distance_3\n",
    "    stat_3, p_3 = kruskal(group['Random_3'], group['Distance_3'])\n",
    "\n",
    "    # Speichere Ergebnisse\n",
    "    results.append({\n",
    "        'Method': method,\n",
    "        'Model': model,\n",
    "        'Stat_R1_vs_D1': stat_1,\n",
    "        'p_R1_vs_D1': p_1,\n",
    "        'Stat_R2_vs_D2': stat_2,\n",
    "        'p_R2_vs_D2': p_2,\n",
    "        'Stat_R3_vs_D3': stat_3,\n",
    "        'p_R3_vs_D3': p_3\n",
    "    })\n",
    "\n",
    "# Erstelle ein DataFrame mit den Ergebnissen\n",
    "results_df = pd.DataFrame(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, levene\n",
    "\n",
    "def check_assumptions(data):\n",
    "    # Check for normality using Shapiro-Wilk test\n",
    "    normality_results = {}\n",
    "    for col in data.columns:\n",
    "        stat, p = shapiro(data[col])\n",
    "        normality_results[col] = {'Shapiro-Wilk': {'statistic': stat, 'p-value': p, 'normality': p > 0.05}}\n",
    "\n",
    "    # Check for homogeneity of variances using Levene's test\n",
    "    stat, p = levene(*[data[col] for col in data.columns])\n",
    "    homogeneity_of_variances = {'Levene': {'statistic': stat, 'p-value': p, 'homogeneity': p > 0.05}}\n",
    "\n",
    "    return normality_results, homogeneity_of_variances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reshape_data(data):\n",
    "    reshaped_data = data.melt(var_name='Sampling_Strategy', value_name='Prediction')\n",
    "    return reshaped_data\n",
    "\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "# Post-hoc pairwise comparisons with Dunn-Bonferroni test\n",
    "for model, data in data_dict.items():\n",
    "    print()\n",
    "    dunn_results = posthoc_dunn(reshape_data(data), group_col=\"Sampling_Strategy\", val_col=\"Prediction\", p_adjust='bonferroni')\n",
    "    print(f\"\\nPost-hoc Pairwise Comparisons (Dunn-Bonferroni Test) {model}:\")\n",
    "    print(dunn_results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Annahme: df ist dein DataFrame mit Spalten Random_1, Random_2, Random_3, Method und Model\n",
    "\n",
    "# Liste der Spalten, in denen du den Test durchführen möchtest\n",
    "columns_to_test = ['Random_1', 'Random_2', 'Random_3']\n",
    "\n",
    "# Ein leeres DataFrame, um die Ergebnisse zu speichern\n",
    "results = []\n",
    "models = final_df[\"Model\"].unique().tolist()\n",
    "# Iteriere über jede Spalte, um den Kruskal-Wallis-Test durchzuführen\n",
    "for m in models:\n",
    "    for column in columns_to_test:\n",
    "        # Daten für Method A und Method B filtern\n",
    "        data_method_A = final_df[(final_df['Method'] == 'Jackknife+') & (final_df['Model'] == m)][column]\n",
    "        data_method_B = final_df[(final_df['Method'] == 'CrossValidation+') & (final_df['Model'] == m)][column]\n",
    "\n",
    "        # Kruskal-Wallis-Test durchführen\n",
    "        stat, p_value = kruskal(data_method_A, data_method_B)\n",
    "\n",
    "        # Ergebnisse speichern\n",
    "        results.append({\n",
    "            'Column': column,\n",
    "            'Method A': 'Jackknife+',\n",
    "            'Method B': 'CrossValidation+',\n",
    "            'Model': m,\n",
    "            'Statistic': stat,\n",
    "            'P-Value': p_value\n",
    "        })\n",
    "\n",
    "# Ergebnisse anzeigen oder weiter verarbeiten\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
